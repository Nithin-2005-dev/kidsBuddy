# -*- coding: utf-8 -*-
"""model_training.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/103x-9NA2LMpQp0clkdAYYHmwgbh75Mue
"""

# !pip install pytorch_tabnet

from pytorch_tabnet.tab_model import TabNetRegressor
import torch

# !pip install colorama

# !pip install catboost

from pathlib import Path

import numpy as np
import polars as pl
import pandas as pd

from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import cohen_kappa_score

import lightgbm as lgb

from tqdm.notebook import tqdm

def get_ts_feature(id_path):
    df = pl.read_parquet(id_path / 'part-0.parquet')
    ts_feature = df.describe().filter(
        ~pl.col("statistic").is_in(["count", "null_count"])
    ).select(
        pl.all().exclude(["statistic", "step"])
    ).to_numpy().reshape(-1)

    patient_id = id_path.name.split("=")[1]

    return ts_feature, patient_id

def get_all_ts_feature(parquet_dir) -> pd.DataFrame:
    items = list(Path(parquet_dir).iterdir())
    features = []
    ids = []
    for id_path in tqdm(items):  # ex) "id=00115b9f"
        feature, patient_id = get_ts_feature(id_path)
        features.append(feature)
        ids.append(patient_id)

    columns = [f"stat_{i}" for i in range(len(features[0]))]
    df = pd.DataFrame(features, columns=columns, index=ids)
    return df

df_train = pd.read_csv('/content/train/train.csv')
df_test = pd.read_csv('/content/train/test.csv')
df_sample = pd.read_csv('/content/train/sample_submission.csv')
df_train.shape, df_test.shape, df_sample.shape

df_train_ts = get_all_ts_feature("/content/train/series_train.parquet")
df_train_ts.shape

df_test_ts = get_all_ts_feature("/content/train/series_test.parquet")
df_test_ts.shape

df_train = pd.merge(df_train, df_train_ts, how='left', left_on='id', right_index=True)
df_test = pd.merge(df_test, df_test_ts, how='left', left_on='id', right_index=True)
df_train.shape, df_test.shape

set(df_train.columns) - set(df_test.columns)

COLS = df_test.columns.drop('id')
len(COLS)

df_train['sii'].value_counts(dropna=False)

df_train = df_train.dropna(subset='sii').copy()
df_train.shape

COLS_season = COLS[COLS.str.contains('Season')].to_list()
COLS_season

df_train[COLS_season].isna().sum()

df_test[COLS_season].isna().sum()

for col in COLS_season:
    df_train[col] = df_train[col].astype('category')
    df_test[col] = df_test[col].astype('category')

SEED = 42

cv = StratifiedKFold(5)

def predict_by_threshold(oof_non_rounded, thresholds):
    return np.where(oof_non_rounded < thresholds[0], 0,
                    np.where(oof_non_rounded < thresholds[1], 1,
                             np.where(oof_non_rounded < thresholds[2], 2, 3)))

param = {
    'learning_rate': 0.01,
    'num_leaves': 100,
    'min_data_in_leaf': 10,
    'n_estimators': 200,
    'subsample': 1.0,
    'colsample_bytree': 1.0
}

lgbm = lgb.LGBMRegressor(**param, random_state=SEED)

lgbm.fit(df_train[COLS], df_train['sii'])

THRESHOLDS = [0.6, 1.6, 2.6]

models = []
train_scores = []
test_scores = []

pred_train = []
pred_test = []

for train_idx, test_idx in cv.split(df_train, df_train['sii']):
    df_fold_train = df_train.iloc[train_idx]
    df_fold_test = df_train.iloc[test_idx]
    model = lgb.LGBMRegressor(**param, random_state=SEED)
    model.fit(df_fold_train[COLS], df_fold_train['sii'])

    pred = model.predict(df_fold_train[COLS])
    pred_train.append(pred)
    pred = predict_by_threshold(pred, THRESHOLDS)
    score_train = cohen_kappa_score(df_fold_train['sii'], pred, weights='quadratic')
    pred = model.predict(df_fold_test[COLS])
    pred_test.append(pred)
    pred = predict_by_threshold(pred, THRESHOLDS)
    score_test = cohen_kappa_score(df_fold_test['sii'], pred, weights='quadratic')
    print(f"score_train: {score_train}, score_test: {score_test}")

    models.append(model)
    train_scores.append(score_train)
    test_scores.append(score_test)

train_scores

test_scores



